---
permalink: system-admin/remove-nodes-cluster-concept.html
sidebar: sidebar
keywords: remove, node, cluster, failover, partner, erase, inaccessible
summary: "You can remove unwanted nodes from a cluster, one node at a time. After you remove a node, you must also remove its failover partner. If you are removing a node, then its data becomes inaccessible or erased."
---
= Remove nodes from the cluster
:icons: font
:imagesdir: ../media/

[.lead]
You can remove unwanted nodes from a cluster, one node at a time. After you remove a node, you must also remove its failover partner. If you are removing a node, then its data becomes inaccessible or erased.

.Before you begin

The following conditions must be satisfied before removing nodes from the cluster:

* More than half of the nodes in the cluster must be healthy.

* All data, volumes, and non-root aggregates have been relocated or removed from the node.

** All of the data on the node that you want to remove must have been evacuated. This might include link:../encryption-at-rest/secure-purge-data-encrypted-volume-concept.html[purging data from an encrypted volume].

** All non-root volumes have been link:../volumes/move-volume-task.html[moved] from aggregates owned by the node.

** All non-root aggregates have been link:../disks-aggregates/commands-manage-aggregates-reference.html[deleted] from the node.

* All LIFs and VLANs have been relocated or removed from the node.

** Data LIFs have been link:../networking/delete_a_lif.html[deleted] or link:../networking/migrate_a_lif.html[relocated] from the node.

** Cluster management LIFs have been link:../networking/migrate_a_lif.html[relocated] from the node and the home ports changed.

** All intercluster LIFs have been link:../networking/delete_a_lif.html[removed]. When you remove intercluster LIFs a warning is displayed that can be ignored.

** All VLANs on the node have been link:../networking/configure_vlans_over_physical_ports.html#delete-a-vlan[deleted].

* The node is not participating in any failover relationships.

** Storage failover has been link:../high-availability/ha_commands_for_enabling_and_disabling_storage_failover.html[disabled] for the node.

** All LIF failover rules have been link:../networking/commands_for_managing_failover_groups_and_policies.html[modified] to remove ports on the node.

* If the node owns Federal Information Processing Standards (FIPS) disks or self-encrypting disks (SEDs), link:../encryption-at-rest/return-seds-unprotected-mode-task.html[disk encryption has been removed] by returning the disks to unprotected mode.
** You might also want to link:../encryption-at-rest/sanitize-fips-drive-sed-task.html[sanitize FIPS drives or SEDs].

* If you have LUNs on the node to be removed, you should link:https://docs.netapp.com/us-en/ontap/san-admin/modify-slm-reporting-nodes-task.html[modify the Selective LUN Map (SLM) reporting-nodes list] before you remove the node.
+
If you do not remove the node and its HA partner from the SLM reporting-nodes list, access to the LUNs previously on the node can be lost even though the volumes containing the LUNs were moved to another node.

It is recommended that you issue an AutoSupport message to notify NetApp technical support that node removal is underway.

IMPORTANT: You must not perform operations such as `cluster remove-node`, `cluster unjoin`, and `node rename` when an automated ONTAP upgrade is in progress.

.About this task

* If you are running a mixed-version cluster, you can remove the last low-version node by using one of the advanced privilege commands beginning with ONTAP 9.3:

** ONTAP 9.3: `cluster unjoin -skip-last-low-version-node-check`
** ONTAP 9.4 and later: `cluster remove-node -skip-last-low-version-node-check`

* If you unjoin 2 nodes from a 4-node cluster, cluster HA is automatically enabled on the two remaining nodes.

NOTE: All system and user data, from all disks that are connected to the node, must be made inaccessible to users before removing a node from the cluster. If a node was incorrectly unjoined from a cluster, contact NetApp Support for assistance with options for recovery.



.Steps

. Change the privilege level to advanced:
+
[source,cli]
----
set -privilege advanced
----

. Verify if a node on the cluster holds epsilon:
+
[source,cli]
----
cluster show -epsilon true
----

. If a node on the cluster holds epsilon and that node is going to be unjoined, move epsilon to a node that is not going to be unjoined:

.. Move epsilon from the node that is going to be unjoined
+
[source,cli]
----
cluster modify -node <name_of_node_to_be_unjoined> -epsilon false
----

.. Move epsilon to a node that is not going to be unjoined:
+
[source,cli]
----
cluster modify -node <node_name> -epsilon true
----

. Identify the current master node:
+
[source,cli]
----
cluster ring show
----
+
The master node is the node that holds processes such as `mgmt`, `vldb`, `vifmgr`, `bcomd`, and `crs`.

. If the node you want to remove is the current master node, then enable another node in the cluster to be elected as the master node:

.. Make the current master node ineligible to participate in the cluster:
+
[source,cli]
----
cluster modify -node <node_name> -eligibility false
----
+
This will cause the node to be marked as unhealthy until eligibility is restored in the next step. When the master node become ineligible, one of the remaining nodes is elected by the cluster quorum as the new master.

.. Make the previous master node eligible to participate in the cluster again:
+
[source,cli]
----
cluster modify -node <node_name> -eligibility true
----
. Log into the remote node management LIF or the cluster-management LIF on a node other than the one that is being removed.

. Remove the node from the cluster:
+
[options="header"]
|===
| For this ONTAP version...| Use this command...
a|
ONTAP 9.3
a|
[source,cli]
----
cluster unjoin
----
a|
ONTAP 9.4 and later
a|
With node name:
[source,cli]
----
cluster remove-node -name <node_name>
----

With node IP:
[source,cli]
----
cluster remove-node -cluster_ip <node_ip>
----

|===
If you have a mixed version cluster and you are removing the last lower version node, use the `-skip-last-low-version-node-check` parameter with these commands.
+
The system informs you of the following:

 ** You must also remove the node's failover partner from the cluster.
 ** After the node is removed and before it can rejoin a cluster, you must use boot menu option (4) Clean configuration and initialize all disks or option (9) Configure Advanced Drive Partitioning to erase the node's configuration and initialize all disks.
+
A failure message is generated if you have conditions that you must address before removing the node. For example, the message might indicate that the node has shared resources that you must remove or that the node is in a cluster HA configuration or storage failover configuration that you must disable.
+
If the node is the quorum master, the cluster will briefly lose and then return to quorum. This quorum loss is temporary and does not affect any data operations.

. If a failure message indicates error conditions, address those conditions and rerun the `cluster remove-node` or `cluster unjoin` command.
+
The node is automatically rebooted after it is successfully removed from the cluster.

. If you are repurposing the node, erase the node configuration and initialize all disks:
 .. During the boot process, press Ctrl-C to display the boot menu when prompted to do so.
 .. Select the boot menu option (4) Clean configuration and initialize all disks.
. Return to admin privilege level:
+
[source,cli]
----
set -privilege admin
----

. Repeat the preceding steps to remove the failover partner from the cluster.

// 2024-12-17 ONTAPDOC-2325
// 2024-7-9 ontapdoc-2192
// 2024 Mar 25, Jira 1810
// 2023 Dec 18, Jira 736
// 2023 Apr 17, Git Issue 750
// 2023 Apr 17, Git Issue 849
// 2023 Apr 10, Git Issue 863
// 2023 Jan 12, Git Issue 755
// 2022-06-29, BURT 1485042
// 2022-03-10, BURT 1453521
