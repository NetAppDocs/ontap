---
permalink: disks-aggregates/add-disks-local-tier-aggr-task.html
sidebar: sidebar
keywords: add, expand, aggregate, add drives, add disks, add capacity, local tier, add disks to local tier, add disks to aggregate, increase storage, increase aggregate size, local tier, capacity, disk, expand storage, add drives, add disks, add capacity
summary: "You can add disks to a local tier so that it can provide more storage to its associated volumes."
---

= Add capacity to an ONTAP local tier
:toclevels: 1
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ../media/

[.lead]
You can add disks to an local tier so that it can provide more storage to its associated volumes.

include::../_include/local-tier-aggregate-note.adoc[]


[role="tabbed-block"]
====
.System Manager (ONTAP 9.8 and later)
--

NOTE: Beginning with ONTAP 9.12.1, you can use System Manager to view the committed capacity of a local tier to determine if additional capacity is required for the local tier. See link:../concepts/capacity-measurements-in-sm-concept.html[Monitor capacity in System Manager].

// 2022 Oct 04, ONTAPDOC-589

.Steps

. Select *Storage > Tiers*.

. Select image:icon_kabob.gif[Menu options icon] next to the name of the local tier to which you want to add capacity.

. Select *Add Capacity*.
+
NOTE: If there are no spare disks that you can add, then the *Add Capacity* option is not shown, and you cannot increase the capacity of the local tier.

. Perform the following steps, based on the version of ONTAP that is installed:
+
[cols="30,70"]
|===

h| If this version of ONTAP is installed...  h| Perform these steps...

a| ONTAP 9.8, 9.9, or 9.10.1
a|
. If the node contains multiple storage tiers, then select the number of disks you want to add to the local tier.  Otherwise, if the node contains only a single storage tier, the added capacity is estimated automatically.
. Select *Add*.

a| Beginning with ONTAP 9.11.1
a|
. Select the disk type and number of disks.
. If you want to add disks to a new RAID group, check the check box.  The RAID allocation is displayed.
. Select *Save*.

|===

. (Optional) The process takes some time to complete. If you want to run the process in the background, select *Run in Background*.

. After the process completes, you can view the increased capacity amount in the local tier information at *Storage > Tiers*.

// 2021 Dec 02, BURT 1396563

--

.System Manager (ONTAP 9.7 and earlier)
--

.Steps

. (For ONTAP 9.7 only) Select *(Return to classic version)*.

. Select *Hardware and Diagnostics > Aggregates*.

. Select the local tier to which you want to add capacity disks, and then select *Actions > Add Capacity*.
+
NOTE: You should add disks that are of the same size as the other disks in the local tier.

. (For ONTAP 9.7 only) Select *Switch to the new experience*.

. Select *Storage > Tiers* to verify the size of the new local tier.
--

.CLI

--

.Before you begin

You must know what the RAID group size is for the local tier you are adding the storage to.

.About this task

This procedure for adding partitioned disks to a local tier is similar to the procedure for adding unpartitioned disks. 

When you expand a local tier, you should be aware of whether you are adding partition or unpartitioned disks to the local tier. When you add unpartitioned drives to an existing local tier, the size of the existing RAID groups is inherited by the new RAID group, which can affect the number of parity disks required. If an unpartitioned disk is added to a RAID group composed of partitioned disks, the new disk is partitioned, leaving an unused spare partition.

When you provision partitions, you must ensure that you do not leave the node without a drive with both partitions as spare. If you do, and the node experiences a controller disruption, valuable information about the problem (the core file) might not be available to provide to the technical support.

.Steps

. Show the available spare storage on the system that owns the local tier:
+
`storage aggregate show-spare-disks -original-owner _node_name_`
+
You can use the `-is-disk-shared` parameter to show only partitioned drives or only unpartitioned drives.
+
----
cl1-s2::> storage aggregate show-spare-disks -original-owner cl1-s2 -is-disk-shared true

Original Owner: cl1-s2
 Pool0
  Shared HDD Spares
                                                            Local    Local
                                                             Data     Root Physical
 Disk                        Type     RPM Checksum         Usable   Usable     Size Status
 --------------------------- ----- ------ -------------- -------- -------- -------- --------
 1.0.1                       BSAS    7200 block           753.8GB  73.89GB  828.0GB zeroed
 1.0.2                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.3                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.4                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.8                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.9                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.10                      BSAS    7200 block                0B  73.89GB  828.0GB zeroed
2 entries were displayed.
----

. Show the current RAID groups for the local tier:
+
[source,cli]
----
storage aggregate show-status <aggr_name>
----
+
----
cl1-s2::> storage aggregate show-status -aggregate data_1

Owner Node: cl1-s2
 Aggregate: data_1 (online, raid_dp) (block checksums)
  Plex: /data_1/plex0 (online, normal, active, pool0)
   RAID Group /data_1/plex0/rg0 (normal, block checksums)
                                              Usable Physical
     Position Disk        Pool Type     RPM     Size     Size Status
     -------- ----------- ---- ----- ------ -------- -------- ----------
     shared   1.0.10        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.5         0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.6         0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.11        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.0         0   BSAS    7200  753.8GB  828.0GB (normal)
5 entries were displayed.
----

. Simulate adding the storage to the aggregate:
+
[source,cli]
----
storage aggregate add-disks -aggregate <aggr_name> -diskcount <number_of_disks_or_partitions> -simulate true
----
+
You can see the result of the storage addition without actually provisioning any storage. If any warnings are displayed from the simulated command, you can adjust the command and repeat the simulation.
+
----
cl1-s2::> storage aggregate add-disks -aggregate aggr_test -diskcount 5 -simulate true

Disks would be added to aggregate "aggr_test" on node "cl1-s2" in the
following manner:

First Plex

  RAID Group rg0, 5 disks (block checksum, raid_dp)
                                                      Usable Physical
    Position   Disk                      Type           Size     Size
    ---------- ------------------------- ---------- -------- --------
    shared     1.11.4                    SSD         415.8GB  415.8GB
    shared     1.11.18                   SSD         415.8GB  415.8GB
    shared     1.11.19                   SSD         415.8GB  415.8GB
    shared     1.11.20                   SSD         415.8GB  415.8GB
    shared     1.11.21                   SSD         415.8GB  415.8GB

Aggregate capacity available for volume use would be increased by 1.83TB.
----

. Add the storage to the aggregate:
+
[source,cli]
----
storage aggregate add-disks -aggregate <aggr_name> -raidgroup new -diskcount <number_of_disks_or_partitions>
----
+
When creating a Flash Pool local tier, if you are adding disks with a different checksum than the local tier, or if you are adding disks to a mixed checksum local tier, you must use the `-checksumstyle` parameter.
+
If you are adding disks to a Flash Pool local tier, you must use the `-disktype` parameter to specify the disk type.
+
You can use the `-disksize` parameter to specify a size of the disks to add. Only disks with approximately the specified size are selected for addition to the local tier.
+
----
cl1-s2::> storage aggregate add-disks -aggregate data_1 -raidgroup new -diskcount 5
----

. Verify that the storage was added successfully:
+
[source,cli]
----
storage aggregate show-status -aggregate <aggr_name>
----
+
----
cl1-s2::> storage aggregate show-status -aggregate data_1

Owner Node: cl1-s2
 Aggregate: data_1 (online, raid_dp) (block checksums)
  Plex: /data_1/plex0 (online, normal, active, pool0)
   RAID Group /data_1/plex0/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     shared   1.0.10                       0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.5                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.6                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.11                       0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.0                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.2                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.3                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.4                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.8                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.9                        0   BSAS    7200  753.8GB  828.0GB (normal)
10 entries were displayed.
----

. Verify that the node still has at least one drive with both the root partition and the data partition as spare:
+
[source,cli]
----
storage aggregate show-spare-disks -original-owner <node_name>
----
+
----
cl1-s2::> storage aggregate show-spare-disks -original-owner cl1-s2 -is-disk-shared true

Original Owner: cl1-s2
 Pool0
  Shared HDD Spares
                                                            Local    Local
                                                             Data     Root Physical
 Disk                        Type     RPM Checksum         Usable   Usable     Size Status
 --------------------------- ----- ------ -------------- -------- -------- -------- --------
 1.0.1                       BSAS    7200 block           753.8GB  73.89GB  828.0GB zeroed
 1.0.10                      BSAS    7200 block                0B  73.89GB  828.0GB zeroed
2 entries were displayed.
----

--
====

// 2025-Mar-6, ONTAPDOC-2850
// 2024-12-2, gh-1641
// BURT 1396563, 2021 Dec 02
// BURT 1485072, 2022 Aug 30
// BURT 1409115, 2023 Jan 03
